{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine learning models for pi3k**\n",
    "\n",
    "*This models are based on empirical potentials obtained with docking by means of Smina docking software.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear all variables\n",
    "%reset -f\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "HOUSING_PATH = os.path.join('.', 'datasets')\n",
    "\n",
    "def load_data(filename, housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, filename)\n",
    "    return pd.DataFrame.from_csv(csv_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_actives = load_data('actives_scores_25_3.txt')\n",
    "train_decoys = load_data('decoys_25_3.txt')\n",
    "train_actives['Active'] = 1\n",
    "train_decoys['Active'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_actives = load_data('scores_active.txt')\n",
    "test_decoys = load_data('scores_decoys.txt')\n",
    "test_decoys = test_decoys.sample(n=len(test_actives))\n",
    "test_actives['Active'] = 1\n",
    "test_decoys['Active'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_data(dat1, dat2):\n",
    "    new_dat = pd.concat([dat1, dat2])\n",
    "    new_dat = new_dat.sample(frac=1)\n",
    "    return new_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = merge_data(train_actives, train_decoys)\n",
    "test_set = merge_data(test_actives, test_decoys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_to_labels(dat):\n",
    "    labels = dat[\"Active\"].copy().as_matrix()\n",
    "    new_dat = dat.drop(\"Active\", axis=1)\n",
    "    return labels, new_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels, test_data = split_data_to_labels(test_set)\n",
    "train_labels, train_data = split_data_to_labels(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transorm the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transformer(train):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('VarianceThreshold', VarianceThreshold(threshold=0.0)),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "    num_pipeline.fit(train)\n",
    "    return num_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(transformer, dat):\n",
    "    dat_tr = transformer.transform(dat)\n",
    "    return dat_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = get_transformer(train_data)\n",
    "train_set_tr = transform_data(transformer, train_data)\n",
    "test_set_tr = transform_data(transformer, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dnn_clf(train, train_labels):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    config = tf.contrib.learn.RunConfig()\n",
    "\n",
    "    feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(train)\n",
    "    dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=2,\n",
    "                                             feature_columns=feature_cols, dropout=0.45, config=config)\n",
    "    dnn_clf = tf.contrib.learn.SKCompat(dnn_clf)\n",
    "    dnn_clf.fit(train, train_labels, batch_size=50, steps=100000)\n",
    "    \n",
    "    return dnn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc(clf, test, test_labels):\n",
    "    from sklearn.metrics import roc_auc_score, log_loss, accuracy_score, f1_score\n",
    "    \n",
    "    y_pred = clf.predict(test)\n",
    "    roc_auc = (roc_auc_score(test_labels, y_pred['probabilities'][:,1]))\n",
    "    print(accuracy_score(test_labels, y_pred['classes']))\n",
    "    print(f1_score(test_labels, y_pred['classes']))\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = get_dnn_clf(train_set_tr, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(get_auc(clf, test_set_tr, test_labels))\n",
    "print(get_auc(clf, train_set_tr, train_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
